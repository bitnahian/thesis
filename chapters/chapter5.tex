\chapter{Conclusions}
\label{chapter:conclusion}
% text suggestions by Uwe
The recent advanced in machine learning and computational capabilities have made it possible to deploy machine learning techniques in various scenarios. 
In this thesis, we investigated the use of reinforcement learning to automate the physical design in distributed databases. In order to do so, several challenges had to be overcome:
\begin{itemize}
    \item Building a mechanism to calculate query-features from a given query workload using cardinality estimates from the query optimiser. This process certainly highlighted one of our key contributions, where we manage to tie in both rich query features and query optimiser inputs into the DRL model.
    \item Integrating query-features as part of the state-model was quintessential to the success of this thesis. This step required a sound sense of topological modelling of the DRL state, and it enabled the DRL agent to mimic the approach a database administrator would take to solve the partitioning problem.
    \item Modifying the offline model to enable query-featurised online training was an engineering challenge that we needed to overcome. Despite our current approach giving us good results, we would like to explore additional tensor slicing strategies in the future to preserve offline-model weights and add randomised weights for query optimiser inputs.
    \item Designing custom APIs to enable dynamic repartitioning in System-X. This process required a lot of development time and communication with System-X engineers to come to an acceptable solution.
    \item Continuously deploying cloud infrastructure for model-training and evaluation was a necessary step in order to reduce AWS cloud expenses and deploy clusters of variable sizes when required.
\end{itemize}
 
The resulting partitioning advisor approach proved to be quite capable.
In an experimental evaluation using a commercial distributed in-memory database and the TPC-CH benchmark, the proposed method was able to propose a data sharing scheme that clearly outperformed the standard heuristics, and even the previous advisor from previous work \cite{Hilprecht:2019:TLP:3329859.3329876} such as partitioning by suggesting non-obvious partitioning schemes which included maximum attribute composite key partitionings, e.g. \texttt{Order, NewOrder} and \texttt{OrderLine} co-partitioned by \texttt{(Order-Id,} \texttt{District-Id, Warehouse-Id)}.
This was possible due to two reasons: Firstly, our approach supports composite partitioning keys, a feature available in System-X. Secondly and more importantly, we integrated the optimizer output into the online learning phase.  

There are also some limitations though. While the proposed approach in general offers a faster conversion of the learned model, it still requires a considerable amount of training time.
In our experiments, this was up-to 52,177 s ($\approx 14.5$ hours) for the online model. This included 30\% of the actual data repartitioning for a TPC-CH size of 1 GB ($SF = 10$). This is a considerable training time, and also only for one database schema, one workload scenario and quite a small data size. If we would want to train for multiple different scenarios, the training time would considerably be longer. Though on the positive side this is needed only once. The trained advisor could then be included with the corresponding product and be used in various different user settings.

There are several possible future directions for research in this space, as discussed in section~\ref{sec:FutureWork}.

Overall, the approach is promising and the idea to integrate the query optimiser with the learning phase offers a clear improvement over a self-coded cost model. 
Using dedicated offline and online phases allows to adapt to hardware properties in the learned model. Using the output of the query optimizer allows to adjust to the capabilities of different database systems or product releases. This approach would be particularly useful in ready-to-go scale out database solutions or Database-as-a-Service (DBaaS) solutions. Commercial cloud providers can easily train and retrain several models for multiple tenants concurrently in order to reduce compute costs for auto-scaling solutions as well as network traffic, which would be beneficial for both customers and cloud providers.

\section{Lessons Learned}
Building a Deep Reinforcement Learning, which is closely tied to a distributed database had its many hurdles. During that process, we encountered many unprecedented problems which required us to adapt our methodology. 

While using System-X had its many benefits, e.g. fast in-memory computation and composite key sharding, which were crucial to our development and success, it posed multiple issues as discussed in Section~\ref{sec:sysx-limitations}. The lack of built-in support for dynamic repartitioning was a difficult problem, which we circumvented using a mixture of DML + DDL scripts. Using this approach not only hindered our total training time (Section~\ref{sec:discussion-training-time}), but also slowed down our development process and impeded us from evaluating our models for synthetic benchmarks other than TPC-CH due to the requirement of writing custom repartitioning scripts for every schemata. 

Additionally, we needed to implement fail-safety mechanisms for unsupported queries, and adapt our algorithm to penalise unsupported queries. Prior to doing so, the model would highly reward failed queries as they executed quicker than successful queries. The DRL agent would then incorrectly suggest partitioning schemes, which would prioritise erroneous queries. During this process, while our DRL agent tried non-obvious partitionings, it triggered a bug in System-X's query optimiser, which prevented System-X from running certain query shapes. The issue was for certain shapes of \texttt{IN} subselects, which would prevent System-X from executing the query. This goes to show that even commercial software has bugs, which have the potential to be incorrectly documented in the user manuals. The error codes and their descriptions have been included in Appendix~\ref{appendix:6}.

However, our lessons from Section~\ref{sec:benefits-query-featurisation} were perhaps some of the most surprising outcomes of this thesis. We traditionally argue that distributed query performance is generally dominated due to performance bottlenecks of data shuffling over the network. However, our introspection into memory and network usage showed that memory usage was the dominant bottleneck in terms of System-X's performance for our workload baselines and experimental setup. While counter-intuitive, we saw a similar pattern between Heuristics 1 and 2, which is also consistent with what \citeauthor{Hilprecht:2019:TLP:3329859.3329876} observed in their measurements with System-X. Thus, it was quite surprising to discover that our query-featurised model was able to learn a partitioning strategy which leveraged on a compromise between network traffic and memory usage.

Lastly, our final lesson came from observing the convergence of the DRL models across multiple episodes. We discovered that our query-featurised RL model converged to a slightly less optimal partitioning scheme after already having discovered a better one in earlier episodes. We argue that this primarily happened because of the DRL agent receiving imprecise query runtimes due to the effects of random variables such as network latency or hardware performance (Section \ref{sec:limitations-of-online-phase}). 

\section{Future Work}
\label{sec:FutureWork}
For future work, there are multiple avenues we would like to explore. However, the order of priority starts with addressing the limitations of our evaluation (Section~\ref{sec:discussion-limitation-evaluation})In particular, we would definitely like to extend our current implementation to adapt to dynamic query workloads so that our model can support far more general query workloads than fixed ones. We would also like to explore the inclusion of other query optimiser operations in our DRL state representation and compare the proposed models to what we have produced.  We would also like to extend the modularity of our approach to different query optimisers in different distributed database solutions and evaluate our approach against heuristics and benchmarks. 



Additionally, it would also be interesting to explore multi-agent Deep Reinforcement Learning techniques to produce a committee of experts for multiple query workload frequencies. Another interesting avenue of future work is to use our approach for transactional workloads or combined systems for analytical and transactional workloads. One more interesting approach would be to use our existing architecture to produce a real-time strategy for training the DRL agent in a RDBMS setting, similar to the work done in \cite{DBLP:conf/sigmod/AbdelhamidA20} for a MapReduce setting.

