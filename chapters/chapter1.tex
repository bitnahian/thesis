\chapter{Introduction}

\section{Motivation}

In this era of Big Data, data-driven applications rely on the efficient and timely analysis of large datasets. This requires a scalable data analysis platform such as distributed database systems which run on a cluster of multiple computer nodes that share the workload and that can scale easily with increasing data volumes or query workloads by adding more nodes. Distributed database systems are however difficult to configure and optimise, in particular for complex analytical workloads which include many join operations between different tables. State-of-the-practice is to use a manual approach based on heuristics which easily can lead to sub-optimal data placements. This in turn can lead to longer execution times. On a cloud-based infrastructure, this also leads to higher costs because of additional network traffic and more computing resources being needed. 

This thesis looks at the idea of automating the data placement decisions using a machine learning-based (ML-based) partitioning advisor. The general idea is to train a partitioning advisor component using Reinforcement Learning with different potential query workloads, such that it 'learns' the best physical data placement in terms of data partitioning (storing table fragments across multiple nodes) and data replication (storing the copies of a table on multiple nodes). Once a corresponding data placement model has been learned, the advisor can then be used as an automatic component of a distributed database to decide automatically given the current database schema and the workload how to place the data for best performance.

% A \textbf{parallel database system} improves on paralellising operations such as loading data, building indexes and evaluating queries \cite{Ramakrishnan:2002:DMS:560733}

Distributed and parallel database systems have become a corner stone of large-scale data warehousing and data analysis. In a \textbf{distributed database system} (DBMS), data is physically spread across different sites, and each site is typically managed by a DBMS capable of running independently. In such systems, the locality of data significantly impacts query optimisation and processing, concurrency control and recovery. The distribution of data is primarily motivated by three factors - i) \textbf{increased availability of data}, ii) \textbf{distributed access to data} and iii) \textbf{analysis of data} \cite{Ramakrishnan:2002:DMS:560733}. 

The data stored in applications in a distributed database system require to be placed across different sites. The two basic forms of placing data are: i) \textbf{partitioned} and ii) \textbf{replicated}. In the partitioned scheme the database is divided into a number of disjoint partitions which are then placed at different sites. Replicated designs can either be \textbf{fully replicated}, where the entire database is copied at each location or \textbf{partially replicated}, where only certain partitions of the database are selectively chosen to be replicated across multiple sites, but not all of them \cite{ozsu2011principles}. 

Commercial products such as Microsoft Azure SQL Data Warehouse or Amazon Redshift provide ready-to-use scale-out database solutions for OLAP-style workloads in the \textbf{cloud}. Because of the aforementioned reasons, customers need to make important design decisions for the physical data layout, such as selecting the partitioning schemes for the data which are traditionally made by database administrators (DBAs). However, finding and defining suitable partitioning schemes is a difficult task even for experienced DBAs. This is because the DBA has to understand the physical query execution for the specific query workloads in order to optimise the performance of the DBMS \cite{jindal2011relax}. 

Partitioning a database optimally is a non-trivial task and hence different partitioning schemes can significantly improve the overall performance. For example, analytical queries often involve multiple joins over large relations. When two relations which are co-partitioned on the same join attribute need to be joined, computation costs can be significantly reduced if the join operation is executed locally on the node if both the relations are partitioned on the same node - thus removing the cost of expensive network transfers. Finding the optimal partitioning scheme for a complex schemata which involve multiple co-partitioning strategies and join paths is a non-trivial task since it not only depends on the database schemata but also other factors such as table sizes, the query workload (i.e., which joins are actually important and how often tables are joined), or hardware characteristics such as network speed. 

Historically, a lot of research in finding the best partition schemes has involved mathematical programming in order to minimise the combined cost of storing the database, processing transactions against it, and message communication among sites. The general problem is considered to be an NP-hard problem \cite{ozsu2011principles}. As such, most proposed solutions are based on heuristics \cite{navathe1984vertical, agrawal2004integrating, agrawal2006automatic, bruno2007online, bruno2008constrained, kimura2010coradd, ozmen2010workload, curino2010schism, quamar2013sword, DBLP:conf/sigmod/ZhouBL12, DBLP:conf/sigmod/NehmeB11}. However, these techniques work only for simple star-schema-like databases. Or they primarily rely on cost estimates from the query optimiser and find a solution by considering finding the partitioning scheme as an optimisation problem. As such, the advisor not only relies on often inaccurate cost estimates which do not reflect the real execution costs for complex multi-join queries but more importantly the advisor cannot easily generalise to new (unseen) workloads without re-running the optimisation procedure for every new workload or mix. 
\section{Contributions}
\label{contribs}

For a successful ML-based approach, there are several challenges to be overcome. The data placement problem for given workloads has to be formalised into corresponding states and actions representations. A further challenge addressed by this thesis is how to best incorporate the effects of hardware effects in an actual online database cluster, such as varying network speeds or main-memory capacities. In this regard, we propose to introduce an explicit online phase so that the partitioning advisor can learn the effects of the hardware configuration from the actual query execution times.  
And lastly, we need different optimisation techniques to avoid exorbitant training times, for example by using an offline phase before the online training phase to rule-out the most sub-optimal data placements, as well as various other optimisations such as query caching and early model convergence. 
 
The work in this Honours thesis is based on the ideas of \citeauthor{Hilprecht:2019:TLP:3329859.3329876}, who initially developed the concept of a RL-based partitioning advisor for distributed databases
using a combined offline/online learning model \cite{Hilprecht:2019:TLP:3329859.3329876,DBLP:conf/sigmod/HilprechtBR20}. This thesis extends \citeauthor{Hilprecht:2019:TLP:3329859.3329876}'s initial work in multiple important directions: \textbf{Firstly}, it introduces query featurisation which allows to abstract from query workload variations by considering the normalised query execution plans. \textbf{Secondly} and most importantly, this thesis connects the online training phase with
the query optimiser of the database system so that the cost estimates of the database can be taken into account too. As we will show in the performance evaluation, this can greatly reduce both the training time and lead to better partitioning schemes than with a hand-written query cost model as used by \citeauthor{Hilprecht:2019:TLP:3329859.3329876}. \textbf{Thirdly}, the thesis extends the state model to also support co-partitioning schemes with composite partition keys, which leads to a clear improvement in the resulting chosen physical designs. 

The thesis' approach is evaluated with a commercial distributed database using the TPC-CH benchmark. It shows that the proposed RL models outperform manual partitioning heuristics and the previous RL-based approach by \citeauthor{Hilprecht:2019:TLP:3329859.3329876}.
% In this thesis, we explore \texttt{RL4DBPartitioning}, where we make a case for Deep Reinforcement Learning (DRL) for learning an advisor that can suggest good database partitioning schemes. In this thesis, we expand upon the work performed by \citeauthor{Hilprecht:2019:TLP:3329859.3329876} in \cite{Hilprecht:2019:TLP:3329859.3329876}. They successfully implement and deploy a Deep Reinforcement Learning advisor, which is not only capable of finding partitions that outperform existing approaches for automated data partitioning design, but that it can also easily adjust to different deployments. This approach is discussed in further detail in Section~\ref{db_partitioning}. 

% To summarise, we aim to extend the DRL agent by making the following contributions:
% \begin{itemize}
%     \item We extend the online model developed by \citeauthor{Hilprecht:2019:TLP:3329859.3329876} to consider compound key partitioning schemes as opposed to just single key partitioning schemes.
%     \item We want to extend the partitioning agent to be more \textbf{query-aware} as opposed to just learning from monitoring the rewards for different workloads.
%     \item We would like to evaluate the effectiveness of the new models against heuristic based approaches and test it under synthetic benchmarks. 
% \end{itemize}

\section{Outline}
To begin, we provide a background of the relevant material that will be needed for the rest of this thesis. Such as a brief introduction to partitioning strategies and join algorithms; as well as a brief discussion of advanced partitioning techniques and the query-awareness of different approaches (Chapter~\ref{chapter:background}). Afterwards, we formally define Deep Q-Reinforcement Learning in the context of a database partitioning task (Chapter~\ref{db_partitioning}).
Following the formulation, we discuss our methods and approach towards creating a Deep Reinforcement Learning agent for database partitioning, wherein we discuss our three new contributions and their implementations (Chapter~\ref{Methods}). In the next chapter, we introduce our experiment setup and baselines; and evaluate the effectiveness and the performance of our proposed ML-based partitioning advisor. Our models are evaluated on synthetic database benchmarks and compared against heuristics-based approaches and existing Deep Reinforcement Learning based techniques (Chapter~\ref{chapter:experimental-evaluation}).
We conclude our thesis by providing a final discussion on the overall results, the lessons we learned and some concluding remarks (Chapter~\ref{chapter:conclusion}).